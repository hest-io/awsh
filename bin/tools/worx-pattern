#!/usr/bin/env python3

import os
import yaml
import json
import click
import re
import functools

import ruamel.yaml
from ruamel.yaml.comments import CommentedMap, CommentedSeq
from io import StringIO

from typing import Any, List, Optional, Dict
from pydantic import BaseModel, ConfigDict, model_validator, ValidationError

from jinja2 import Environment, FileSystemLoader

from awshutils.logger import AWSHLog
from awshutils import check_imports, clean_up

from rich import print

###############################################################################
# CONFIG - Begin
###############################################################################



###############################################################################
# CONFIG - End (Do Not Edit Below)
###############################################################################

_log = AWSHLog(__file__)
check_imports()


###############################################################################
# Classes for Pydantic model
###############################################################################

class PrefixTokens(BaseModel):
    org: str = "HIO"
    lifecycle: str = "dev"
    tenant: Optional[str] = None
    location: Optional[str] = None


class DefaultTags(BaseModel):
    model_config = ConfigDict(extra="allow")
    WorxPatternManager: str


class DocGenConfiguration(BaseModel):
    model_config = ConfigDict(extra="allow")
    ignored_paths: List[str] = ["one", "two"]


class CommonConfig(BaseModel):
    prefix_tokens: PrefixTokens
    default_tags: DefaultTags
    _debug_enabled: Optional[bool] = False
    docgen: Optional[DocGenConfiguration] = {}


class Feature(BaseModel):
    model_config = ConfigDict(extra="allow")
    enabled: bool
    md: Dict[str, Any] = {}

    @model_validator(mode='before')
    @classmethod
    def preprocess_metadata(cls, data):
        if isinstance(data, dict):
            # build a dict with any keys that start with "WORX_"
            md_dict = {key: value for key, value in data.items() if key.startswith("WORX_")}
            # move those meta-data keys into the "md" dict after transforming their cleaning up their keys
            data["md"] = { k.replace("WORX_", "").lower(): v for k,v in md_dict.items() }
            # remove any of the keys from the data that are now present in the meta-data
            data = { k: v for k,v in data.items() if k not in md_dict.keys() }
        return data

    @model_validator(mode='after')
    def ensure_minimum_metadata(self):
        required_metadata = ["description", "disruptive"]
        for k in required_metadata:
          if k not in self.md.keys():
            raise ValueError(f"Required meta-data comment missing for 'WORX_{k.upper()}'")
        return self


class Defaults(BaseModel):
    model_config = ConfigDict(extra="allow")


class UnitDefaults(BaseModel):
    model_config = ConfigDict(extra="allow")
    unit_features: Dict[str, Feature]


class PatternPayload(BaseModel):
    model_config = ConfigDict(extra="allow")
    defaults: Dict[str, Any]
    unit_defaults: Optional[UnitDefaults] = { }


class Configuration(BaseModel):
    common_config: CommonConfig
    pattern_features: Dict[str, Feature]
    pattern_payload: PatternPayload


###############################################################################
# Functions
###############################################################################


def exit_with_error(message):
    _log.error(message)
    clean_up(-1)


def j2f_is_required(value):
    if "required" in f"{value}".lower():
        return True
    return False


def j2f_to_code_snippet(value):
    json_content = None
    yaml_content = None
    simple_content = None
    # _log.debug(f"value = {value}")

    try:
        json_content = json.dumps(json.loads(f"{value}"), indent=2)
    except json.decoder.JSONDecodeError as e:
        _log.debug(f"Failed during attempted JSON transformation {e}")

    try:
        if '\n' in value:
          yaml_content = f"{value}"
        else:
          yaml_content = yaml.dump(value, width=2147483647)
    except (yaml.YAMLError, KeyError, IndexError, ValueError, TypeError) as e:
        _log.debug(f"Failed during attempted YAML transformation {e}")

    try:
        simple_content = f"{value}"
    except SyntaxError as e:
        _log.warning(f"Failed during attempted default transformation {e}")

    #_log.debug(f"json_content = {json_content}")
    #_log.debug(f"yaml_content = {yaml_content}")
    #_log.debug(f"simple_content = {simple_content}")
    return next((c for c in [json_content, yaml_content, simple_content] if c is not None), f"{value}")


def j2f_is_simple_variable(value):
    if value is None or f"{value}".lower() in ["null", "none"]:
        return True
    if isinstance(value, (int, float, str)):
        if isinstance(value, str) and f"{value}".count("\n") > 0:
            return False
        if isinstance(value, str) and len(f"{value}") > 80:
            return False
        if isinstance(value, str) and "\n" not in value:
            return True
        elif isinstance(value, list):
            for item in value:
                if not j2f_is_simple_variable(item):
                    return False
            return True
        return True
    if isinstance(value, (dict, set)):
        return False
    return True


def j2f_bool_to_feature_flag(variable):
    if isinstance(variable, bool):
        return "Enabled" if variable else "Disabled"
    elif isinstance(variable, str):
        variable_lower = variable.lower()
        if variable_lower in ["true", "1", "yes", "on"]:
            return "Enabled"
    return "Disabled"


def j2f_is_disruptive(variable):
    if f"{variable}".lower() in ["true", "1", "yes"]:
        return True
    return False


def yaml_has_path(yaml_content, target_path):
    _log.debug(f"Testing for presence of {target_path} in YAML tree")
    def check_path(obj, path_parts):
        if not obj:
            return False
        if len(path_parts) == 1:
            return path_parts[0] in obj
        else:
            next_key = path_parts[0]
            if isinstance(obj, dict) and next_key in obj:
                return check_path(obj[next_key], path_parts[1:])
            elif isinstance(obj, list) and next_key.isdigit():
                index = int(next_key)
                if 0 <= index < len(obj):
                    return check_path(obj[index], path_parts[1:])
            return False

    path_parts = target_path.split('.')
    return check_path(yaml_content, path_parts)


def yaml_get_value_by_dotpath(yaml_content, path):
    return functools.reduce(lambda c, k: c[k], path.split('.'), yaml_content)


def yaml_remove_keys_with_dotpath(yaml_data, dotpath_expressions):
    for entry in dotpath_expressions:
      yaml_data = yaml_remove_key_with_dotpath(yaml_data, entry)
    return yaml_data


def yaml_remove_key_with_dotpath(yaml_data, dotpath_expression):
    def recursive_remove(obj, keys):
        if isinstance(obj, CommentedMap):
            for key in list(obj):
                new_keys = keys + [key]
                if '.'.join(new_keys) == dotpath_expression:
                    del obj[key]
                else:
                    recursive_remove(obj[key], new_keys)
        elif isinstance(obj, CommentedSeq):
            for i, item in enumerate(obj):
                new_keys = keys + [str(i)]
                recursive_remove(item, new_keys)

    YAML = ruamel.yaml.YAML()
    data = YAML.load(yaml_data)
    recursive_remove(data, [])

    # Use a StringIO to capture the output
    output_stream = StringIO()
    YAML.dump(data, output_stream)
    return output_stream.getvalue()


def load_and_validate(file):

    try:
        with open(os.path.expanduser(file), 'r') as fh:
            file_contents = fh.read()

        _log.debug(f"Performing pre-processor transform for WORX comments")
        # Use regular expression to replace '# WORX_...' with 'WORX_:...'
        modified_contents = re.sub(r'#\s*WORX_\s*(.*?)\s*=', r'WORX_\1: ', file_contents)

        yaml_content = yaml.safe_load(modified_contents)

        if yaml_has_path(yaml_content, "common_config._docgen.ignored_paths"):
            paths = yaml_get_value_by_dotpath(yaml_content, "common_config._docgen.ignored_paths")
            _log.debug(f"Pruning {len(paths)} nodes from YAML tree")
            modified_contents = yaml_remove_keys_with_dotpath(modified_contents, paths)

        config_data = yaml.safe_load(modified_contents)
        _log.debug(f"Pre-processor transform complete")

    except FileNotFoundError:
        _log.error(f"Input file '{file}' not found.")

    # Parse and validate the YAML data using Pydantic
    try:
        pattern_config = Configuration(**config_data)
        _log.info("YAML configuration is valid.")
        return pattern_config

    except Exception as e:
        exit_with_error(f"YAML configuration is invalid: {e}")


def render_model_with_template(template_base, template_name, model):
    _log.debug(f"Processing data using template {template_base}/{template_name}")

    # Create the jinja2 environment. Notice the use of trim_blocks,
    # which greatly helps control whitespace.
    j2_env = Environment(loader=FileSystemLoader(template_base), trim_blocks=True)

    # Add our custom filters
    j2_env.filters["j2f_is_simple_variable"] = j2f_is_simple_variable
    j2_env.filters["j2f_bool_to_feature_flag"] = j2f_bool_to_feature_flag
    j2_env.filters["j2f_is_required"] = j2f_is_required
    j2_env.filters["j2f_is_disruptive"] = j2f_is_disruptive
    j2_env.filters["j2f_to_code_snippet"] = j2f_to_code_snippet

    template = j2_env.get_template(template_name)
    rendered_data = template.render(data=model)
    return rendered_data


def debug_option(*_, **kwargs):
    """
    Add a ``--debug`` option to print out a stacktrace when an error occurs.
    """

    def callback(ctx, _, value):
        if not value or ctx.resilient_parsing:
            return

        import logging
        _log.setLevel(logging.DEBUG)

    kwargs.setdefault("is_flag", True)
    kwargs.setdefault("expose_value", False)
    kwargs.setdefault("help", "Show more verbose logging")
    kwargs["callback"] = callback
    return click.decorators.option("--debug", **kwargs)


@click.group(context_settings={"help_option_names": ["-h", "--help"]})
@click.pass_context
@debug_option()
def worx_pattern_tool(ctx):
    pass


@worx_pattern_tool.command()
@click.argument("file")
@click.pass_context
@debug_option()
def validate(ctx, file):
    """Validate YAML file syntax and required keys."""
    _log.debug(f"validate {file}")
    load_and_validate(file)


@worx_pattern_tool.command()
@click.option(
    "-t",
    "--template-root",
    default=f"{os.getenv('AWSH_ROOT')}/etc/worx.d/templates",
    help="Path to the templates base dir. Defaults to using ${AWSH_ROOT}/etc/worx.d/templates",
)
@click.argument("file")
@click.argument("output")
@click.pass_context
@debug_option()
def docgen(ctx, template_root, file, output):
    """Create documentation in Markdown format."""

    _log.debug(f"template_root set to {template_root}")
    ctx.obj = {"template_root": template_root}
    # template_root = ctx.obj["template_root"]

    # Your documentation generation code here
    _log.debug(f"docgen reading from {file}")
    _log.debug(f"docgen using templates from {template_root}")
    _log.debug(f"docgen writing to {output}")

    pattern_config = load_and_validate(file)

    content = []
    # for section in [ "common_config", "pattern_features", "pattern_payload" ]:
    content.append(render_model_with_template(template_root, "PatternFeatures.j2", pattern_config.pattern_features))
    content.append(render_model_with_template(template_root, "PatternOptions.j2", pattern_config.pattern_payload.defaults))

    if hasattr(pattern_config.pattern_payload, "unit_defaults"):
      if hasattr(pattern_config.pattern_payload.unit_defaults, "unit_features"):
        content.append(render_model_with_template(template_root, "UnitFeatures.j2", pattern_config.pattern_payload.unit_defaults.unit_features))

      unit_options = { k: v for k,v in pattern_config.pattern_payload.unit_defaults if k != "unit_features" }
      content.append(render_model_with_template(template_root, "UnitOptions.j2", unit_options))

    _log.info(f"Writing to {output}")
    with open(os.path.expanduser(output), "w") as fh:
        for section in content:
            fh.write(section)


###############################################################################
# Main
###############################################################################
if __name__ == "__main__":
    worx_pattern_tool()
